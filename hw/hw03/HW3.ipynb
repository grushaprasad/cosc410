{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f70ec69-3252-4eac-9e1e-9d61ae141059",
   "metadata": {},
   "source": [
    "# HW 3: RNN Encoder\n",
    "\n",
    "### COSC 410B: Spring 2025, Colgate University\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abbe31-f303-483b-99e4-3e22f0faae09",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this homework you will build an RNN encoder and use that to train a classifier that classifies sentences as either being grammatical or ungrammatical. Specifically, you will be working with the BLiMP dataset([paper](https://arxiv.org/abs/1912.00582), [link to the dataset on Huggingface](https://huggingface.co/datasets/nyu-mll/blimp)). \n",
    "\n",
    "BLiMP has several data for different kinds of grammatical phenomena. You will start by training a model on one simple phenomenon to make sure that you have the pipeline set up. Then you will explore training and evaluating the model on different phenomena.\n",
    "\n",
    "**There are a lot of parts of this homework that are underspecified, and will require you to look up how to do stuff we haven't covered (such as how to work with huggingface datasets). This is intentional. The goal is that doing this and productively struggling will help you when you work on your final project.** \n",
    "\n",
    "### What to submit\n",
    "\n",
    "* `RNNEncoder.py` which has your RNN Encoder class\n",
    "* `ClassificationDataset.py` which is a class that stores the classification data in a format that can be fed into an RNN (i.e., encodes words, converts them to tensors, etc)\n",
    "* `util.py` which has all of the other functions you need, such as those for training, evaluation, etc.\n",
    "* `HW3.ipynb` (i.e., this notebook) where you will actuall train the model, report the results etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fc10d-fb4e-4a03-929e-684f8b570da8",
   "metadata": {},
   "source": [
    "## Part 1: Learning one phenomenon\n",
    "\n",
    "Train RNN models on the `anaphor_gender_agreement` portion of BLiMP. Note, the BLiMP dataset linked on huggingface doesn't come with train, validation, and test split. So you will need split the data yourself. Use a 80-10-10 split for train, validation, and test. \n",
    "\n",
    "**Note: I was able get ~80\\% accuracy on held out test data by training the model on 20 epochs or so with very minimal hyperparameter tuning.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1ec28-e509-484c-b4b8-0ca206ebf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add as many code and markdown chunks as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd988c-0ebb-4f6f-8a4e-875eb360b56a",
   "metadata": {},
   "source": [
    "## Part 2: Extending to multiple phenomena\n",
    "\n",
    "Pick at least three other parts of BLiMP. Create train-test-val datasets with all of these portions (just one train, one val, one test). Train and evlauate RNN models w\n",
    "\n",
    "Train RNN models on all of these portions (at the same time) and evaluate them on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34d89d-1651-4a4b-b3c6-97b6660c6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add as many code and markdown chunks as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba6f0b-a962-4ff5-bd90-06201d78fdde",
   "metadata": {},
   "source": [
    "## Part 3: Evaluating generalization to unseen phenomena\n",
    "\n",
    "Evaluate the best model from the previous step on at least one other phenomenon it hasn't been trained on. Interpret your results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3062db-d069-4270-a1d6-81d3209fec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add as many code and markdown chunks as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea6065-964a-4261-907f-c4cce29d9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc410",
   "language": "python",
   "name": "cosc410"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
