{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523d2233-700b-47c7-bd44-09c629043151",
   "metadata": {},
   "source": [
    "# HW 2: Multinomial logistic regression\n",
    "\n",
    "### COSC 410B: Spring 2025, Colgate University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8decdd1-b0bd-4fde-b93f-b1f3cb312db2",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this homework you will build on Lab 3 and generate synthetic multionomial logistic regression data and implement a model from scratch using pytorch that can fit this data. Apart from basic transformations like `log`, `mean` or `sum` or linear algebraic operations such as matrix multiplication, you are only allowed to use the following pytorch classes and functions. \n",
    "\n",
    "* `torch.nn.Linear`\n",
    "* `torch.nn.functional.softmax`\n",
    "* `torch.optim.SGD`\n",
    "* `torch.argmax`\n",
    "\n",
    "**If you are unsure about whether you can use something, please ask me!** \n",
    "\n",
    "You will work with three files for this HW: \n",
    "\n",
    "1. `MultinomialLogisticRegression.py` where you will implement your model\n",
    "2. `util.py` where you will add code to generate synthetic training data, train the model, evaluate the model etc.\n",
    "3. `HW2.ipynb` where you will actually generate the data, create instances of the model, train it, and report the models' performance. You will also answer questions in this file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d766ba5-7aa6-4704-b3d2-0596d74d8f91",
   "metadata": {},
   "source": [
    "## Part 1: Training on linearly separable data\n",
    "\n",
    "In this part you should:\n",
    "\n",
    "1. Create synthetic classification data with 3 classes and 2 input features. The generative process for the data creation should match the assumptions of a multinomial logistic regression model -- i.e., the classes are created from a linear combination of input features and weights. This is similar to how the data created for Lab 3.\n",
    "\n",
    "2. Plot the data to verify that the data you generated is linearly separable. If you find that it isn't clearly linearly separable, then adjust the weights you used to create the data. \n",
    "\n",
    "3. Train the model on the synthetic data using mini-batch gradient descent.\n",
    "\n",
    "4. Use accuracy, precision and recall to evaluate the model on the training data as well as on unseen data that comes from the same distribution as your training data. Discuss the model's performance. You can use existing python packages for these evaluation metrics if you would like.\n",
    "\n",
    "\n",
    "In addition to this, answer the following questions: \n",
    "\n",
    "* How many epochs did you train your model for? How did you decide on this number? Were you convinced that by the end of training the model learned the training data?\n",
    "\n",
    "* In batch-gradient descent, in order to guarantee that the model learns from the training data, it is theoretically important to *shuffle* the batches each epoch such that the examples in batch 1 in epoch 1 are not the same as examples in batch 1 of epoch 2. Explain why you think this is important in general, and why this is not necessary for the synthetic data you created. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d84f6a-6807-4e6d-bf77-180567b8fbf6",
   "metadata": {},
   "source": [
    "## Part 2: Training on data that is not linearly separable\n",
    "\n",
    "In this part you should: \n",
    "\n",
    "1. Modify the process you use to generate the synthetic data in step 1 such that the process does not match the assumptions of a multinomial logistic regression model. In other words, create data that is **NOT** linearly separable. As in part 1, create classification data with 3 classes and 2 input features\n",
    "\n",
    "2. Plot the data to verify that the data you generated is **NOT** linearly separable.\n",
    "\n",
    "3. Train the model on the synthetic data using mini-batch gradient descent.\n",
    "\n",
    "4. Use accuracy, precision and recall to evaluate the model on the training data as well as on unseen data that comes from the same distribution as your training data. Discuss the model's performance. You can use existing python packages for these evaluation metrics if you would like.\n",
    "\n",
    "5. Discuss: what do you notice about the model's performance in this case relative to Part 1? Why do you think these differences exist? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc410",
   "language": "python",
   "name": "cosc410"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
